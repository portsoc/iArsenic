{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e06e1357-aa10-476d-8c62-696dcd7ac915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.ops import unary_union\n",
    "from shapely.affinity import scale\n",
    "from shapely.geometry import Polygon\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6c429f1-ee54-4f25-86f5-728df4bb52db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "\n",
    "# Define a quantization function\n",
    "def quantize_geometry(geometry, precision=6):\n",
    "    def quantize_coords(coords):\n",
    "        return [(round(x, precision), round(y, precision)) for x, y in coords]\n",
    "\n",
    "    if geometry is None:\n",
    "        return geometry\n",
    "    \n",
    "    if geometry.is_empty:\n",
    "        return geometry\n",
    "\n",
    "    # Handle Polygon\n",
    "    if isinstance(geometry, Polygon):\n",
    "        return Polygon(quantize_coords(geometry.exterior.coords))\n",
    "\n",
    "    # Handle MultiPolygon\n",
    "    elif isinstance(geometry, MultiPolygon):\n",
    "        new_polygons = []\n",
    "        for poly in geometry.geoms:  # Use the 'geoms' attribute to access individual polygons\n",
    "            new_poly = Polygon(quantize_coords(poly.exterior.coords))\n",
    "            new_polygons.append(new_poly)\n",
    "        return MultiPolygon(new_polygons)\n",
    "\n",
    "# Load GeoDataFrames and quantize geometries\n",
    "divisions = gpd.read_file('../../preprocessing/geodata/maps/dist/div/div-c005-s020-vw-pr.geojson').to_crs(epsg=32645)\n",
    "divisions['geometry'] = divisions['geometry'].apply(quantize_geometry)\n",
    "\n",
    "districts = gpd.read_file('../../preprocessing/geodata/maps/dist/dis/dis-c005-s020-vw-pr.geojson').to_crs(epsg=32645)\n",
    "districts['geometry'] = districts['geometry'].apply(quantize_geometry)\n",
    "\n",
    "upazilas = gpd.read_file('../../preprocessing/geodata/maps/dist/upa/upa-c005-s020-vw-pr.geojson').to_crs(epsg=32645)\n",
    "upazilas['geometry'] = upazilas['geometry'].apply(quantize_geometry)\n",
    "\n",
    "unions = gpd.read_file('../../preprocessing/geodata/maps/dist/uni/uni-c005-s020-vw-pr.geojson').to_crs(epsg=32645)\n",
    "unions['geometry'] = unions['geometry'].apply(quantize_geometry)\n",
    "\n",
    "mouzas = gpd.read_file('../../preprocessing/geodata/maps/dist/mou/mou-c005-s020-vw-pr.geojson').to_crs(epsg=32645)\n",
    "mouzas['geometry'] = mouzas['geometry'].apply(quantize_geometry)\n",
    "\n",
    "# Generate region keys\n",
    "divisions['region_key'] = divisions['div']\n",
    "districts['region_key'] = districts['div'] + '@' + districts['dis']\n",
    "upazilas['region_key'] = upazilas['div'] + '@' + upazilas['dis'] + '@' + upazilas['upa']\n",
    "unions['region_key'] = unions['div'] + '@' + unions['dis'] + '@' + unions['upa'] + '@' + unions['uni']\n",
    "mouzas['region_key'] = mouzas['div'] + '@' + mouzas['dis'] + '@' + mouzas['upa'] + '@' + mouzas['uni'] + '@' + mouzas['mou']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4ea0aa-1584-46cd-b094-f6d15209c9bd",
   "metadata": {},
   "source": [
    "# Rules for datastructure\n",
    "1. Region keys must be complete, containing no null values\n",
    "2. Region keys must be unique\n",
    "3. Each region (excluding divs) must have a valid parent which it is contained by and labelled by region key as within\n",
    "4. Regions must not overlap\n",
    "5. Regions must be completely contained by parent\n",
    "6. Regions must not contain gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e063ef54-8f19-4ad4-a83f-5a0c75f3a504",
   "metadata": {},
   "source": [
    "# Divisions\n",
    "## Region keys must be complete, containing no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acd5e32b-c7c8-4f89-ae98-b7c444560f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   area        8 non-null      float64 \n",
      " 1   div         8 non-null      object  \n",
      " 2   geometry    8 non-null      geometry\n",
      " 3   region_key  8 non-null      object  \n",
      "dtypes: float64(1), geometry(1), object(2)\n",
      "memory usage: 388.0+ bytes\n",
      "\n",
      "\n",
      "area, div, geometry non-null is 8. df length is also 8\n"
     ]
    }
   ],
   "source": [
    "divisions.info()\n",
    "\n",
    "print('\\n')\n",
    "print('area, div, geometry non-null is 8. df length is also 8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaf2423-f97a-4cd5-9a07-6529bf083873",
   "metadata": {},
   "source": [
    "## Region keys must be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c450119b-4950-4374-890b-9bab0616808c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divion region keys unique\n"
     ]
    }
   ],
   "source": [
    "div_vc = divisions['region_key'].value_counts()\n",
    "\n",
    "if len(div_vc[div_vc > 1]) == 0:\n",
    "    print('divion region keys unique')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c94d7e-422f-4778-ad12-69e6cef0a038",
   "metadata": {},
   "source": [
    "## Each region (excluding divs) must have a valid parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30623641-6a54-4300-9685-7d3f3ecf23a1",
   "metadata": {},
   "source": [
    "divs do not require parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed68a8d-d3bf-4ad1-8476-887a29525359",
   "metadata": {},
   "source": [
    "## Regions must not overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02353569-cec0-4217-9b74-1d4c9689cace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No overlapping regions found.\n"
     ]
    }
   ],
   "source": [
    "overlap_pairs = []\n",
    "\n",
    "for i, geom1 in divisions.iterrows():\n",
    "    for j, geom2 in divisions.iterrows():\n",
    "        if i != j:\n",
    "            if geom1['geometry'].overlaps(geom2['geometry']):\n",
    "                overlap_pairs.append((i, j))\n",
    "\n",
    "# Report the results\n",
    "if overlap_pairs:\n",
    "    print(\"Overlapping regions found:\")\n",
    "    for pair in overlap_pairs:\n",
    "        print(f\"Region {pair[0]} overlaps with Region {pair[1]}\")\n",
    "else:\n",
    "    print(\"No overlapping regions found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d0c66b-af6b-4a45-9f78-c49252fe9a46",
   "metadata": {},
   "source": [
    "## Regions must be completely contained by parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f7a1cc-5f0e-4bfd-acef-68ca86b863ab",
   "metadata": {},
   "source": [
    "divs do not require parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b8fc9c-97fa-4feb-82d6-468777d47ce2",
   "metadata": {},
   "source": [
    "## Regions must not contain gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50f5b28d-35ef-4f2b-b79f-a656437f9c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No parent gap issues\n"
     ]
    }
   ],
   "source": [
    "def check_region_containment(parents, children) -> list:\n",
    "    containment_issues = []\n",
    "\n",
    "    for i, parent in parents.iterrows():\n",
    "        parent_region_key = parent['region_key']\n",
    "        child_regions = children[children['region_key'].str.contains(parent_region_key, regex=False)]\n",
    "\n",
    "        if child_regions.empty:\n",
    "            continue\n",
    "\n",
    "        parent_geometry = parent['geometry']\n",
    "        parent_area = parent_geometry.area\n",
    "\n",
    "        total_child_area = sum(child['geometry'].area for _, child in child_regions.iterrows())\n",
    "        total_intersection_area = sum(child['geometry'].intersection(parent_geometry).area for _, child in child_regions.iterrows())\n",
    "        \n",
    "        if total_child_area < 0.99 * parent_area or total_child_area > 1.01 * parent_area:\n",
    "            containment_issues.append(f'''\n",
    "                Area mismatch for parent region key: {parent_region_key} \n",
    "                Total child area: {total_child_area}, Parent area: {parent_area}\n",
    "            ''')\n",
    "        \n",
    "        if total_intersection_area < 0.99 * parent_area or total_intersection_area > 1.01 * parent_area:\n",
    "            containment_issues.append(f'''\n",
    "                Containment error for parent region key: {parent_region_key} \n",
    "                Total intersection area: {total_intersection_area}, Parent area: {parent_area}\n",
    "            ''')\n",
    "\n",
    "    return containment_issues\n",
    "\n",
    "containment_issues = check_region_containment(divisions, districts)\n",
    "\n",
    "if len(containment_issues) > 0:\n",
    "    print(f'{len(containment_issues)} containment issues found:')\n",
    "    for issue in containment_issues:\n",
    "        print(issue)\n",
    "else:\n",
    "    print(\"No parent gap issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a429691-f84e-40a7-98a0-779ad840fad7",
   "metadata": {},
   "source": [
    "# Districts\n",
    "## Region keys must be complete, containing no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24bd8823-1854-4c54-8451-6648012f29be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 64 entries, 0 to 63\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   area        64 non-null     float64 \n",
      " 1   dis         64 non-null     object  \n",
      " 2   div         64 non-null     object  \n",
      " 3   geometry    64 non-null     geometry\n",
      " 4   region_key  64 non-null     object  \n",
      "dtypes: float64(1), geometry(1), object(3)\n",
      "memory usage: 2.6+ KB\n",
      "\n",
      "\n",
      "area, div, dis, geometry non-null is 64. df length is also 64\n"
     ]
    }
   ],
   "source": [
    "districts.info()\n",
    "\n",
    "print('\\n')\n",
    "print('area, div, dis, geometry non-null is 64. df length is also 64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbc2f95-fd3e-4fa7-9d6d-bebe4dcf7f8b",
   "metadata": {},
   "source": [
    "## Region keys must be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4682b862-7d5e-4aad-b8a6-60d8f9409bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "district region keys unique\n"
     ]
    }
   ],
   "source": [
    "dis_vc = districts['region_key'].value_counts()\n",
    "\n",
    "if len(dis_vc[dis_vc > 1]) == 0:\n",
    "    print('district region keys unique')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2743a81e-35ae-40a8-a42a-6fc142b1ea7a",
   "metadata": {},
   "source": [
    "## Each region (excluding divs) must have a valid parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7883ef6c-f952-4b6f-9fda-7accf31466a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of errors: 0\n",
      "No errors found.\n"
     ]
    }
   ],
   "source": [
    "def find_best_parent(child_geometry, potential_parents):\n",
    "    best_parent = None\n",
    "    max_intersection_area = 0\n",
    "    child_area = child_geometry.area\n",
    "\n",
    "    for idx, parent_row in potential_parents.iterrows():\n",
    "        parent_geometry = parent_row['geometry']\n",
    "        \n",
    "        intersection = child_geometry.intersection(parent_geometry)\n",
    "        intersection_area = intersection.area\n",
    "        \n",
    "        if intersection_area > max_intersection_area:\n",
    "            max_intersection_area = intersection_area\n",
    "            best_parent = parent_row\n",
    "    \n",
    "    intersection_percentage = max_intersection_area / child_area if child_area > 0 else 0\n",
    "    return best_parent, intersection_percentage\n",
    "\n",
    "def get_labelled_parent(child_region, divisions):\n",
    "    region_parent_key = '@'.join(child_region['region_key'].split('@')[:-1])\n",
    "    labelled_parent = divisions[divisions['region_key'] == region_parent_key]\n",
    "    \n",
    "    if len(labelled_parent) == 1:\n",
    "        return labelled_parent.iloc[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def validate_region_parents(regions, parent_regions, parent_level):\n",
    "    count = 0\n",
    "    errors = []\n",
    "\n",
    "    pps = {\n",
    "        'div': divisions,\n",
    "        'dis': districts,\n",
    "        'upa': upazilas,\n",
    "        'uni': unions,\n",
    "        'mou': mouzas,\n",
    "    }\n",
    "    \n",
    "    for i, row1 in regions.iterrows():\n",
    "        err_dict = { 'region': row1, 'errors': [] }\n",
    "        count += 1\n",
    "\n",
    "        potential_parents = parent_regions[parent_regions[parent_level] == row1[parent_level]]\n",
    "\n",
    "        labelled_parent = None\n",
    "        if len(potential_parents) == 0:\n",
    "            print(f\"Cannot find regions labelled parent region {i}\")\n",
    "\n",
    "            potential_parents = pps[parent_level]\n",
    "        else:\n",
    "            labelled_parent = get_labelled_parent(row1, pps[parent_level])\n",
    "    \n",
    "        best_parent, max_area = find_best_parent(row1['geometry'], potential_parents)\n",
    "    \n",
    "        if best_parent is None or (labelled_parent is not None and best_parent['region_key'] != labelled_parent['region_key']):\n",
    "            if best_parent is None:\n",
    "                err_dict['errors'].append('No geographic parent found')\n",
    "                print('No geographic parent found')\n",
    "    \n",
    "            if labelled_parent is not None and best_parent['region_key'] != labelled_parent['region_key']:\n",
    "                err_dict['errors'].append(f\"Best parent region key ({best_parent['region_key']}) does not match labelled parent region key ({labelled_parent['region_key']})\")\n",
    "                print(f\"Best parent region key: {best_parent['region_key']}\")\n",
    "                print(f\"Labelled parent region key: {labelled_parent['region_key']}\")\n",
    "                \n",
    "            fig, ax = plt.subplots()\n",
    "            \n",
    "            if best_parent is not None:\n",
    "                gpd.GeoDataFrame(geometry=[best_parent['geometry']]).plot(ax=ax, linewidth=2, edgecolor='green', facecolor='none', alpha=0.5, label='Geographic Parent')\n",
    "    \n",
    "            if labelled_parent is not None:\n",
    "                gpd.GeoDataFrame(geometry=[labelled_parent['geometry']]).plot(ax=ax, linewidth=2, edgecolor='red', facecolor='none', alpha=0.5, label='Labelled Parent')\n",
    "            \n",
    "            gpd.GeoDataFrame(geometry=[row1['geometry']]).plot(ax=ax, linewidth=2, edgecolor='blue', facecolor='none', alpha=0.5, label='Child')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "    \n",
    "        errors.append(err_dict)\n",
    "    return errors\n",
    "\n",
    "errors = validate_region_parents(districts, divisions, 'div')\n",
    "\n",
    "total_errors = sum(len(err_dict['errors']) for err_dict in errors)\n",
    "print(f'Total number of errors: {total_errors}')\n",
    "\n",
    "if total_errors == 0:\n",
    "    print(\"No errors found.\")\n",
    "else:\n",
    "    print(f\"Errors found: {total_errors}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d481a2d7-2b48-4193-881e-cd4c7bd61ee2",
   "metadata": {},
   "source": [
    "## Regions must not overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adc14bca-436b-4073-9886-7e5acd97aee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 64 out of 64 items.\n",
      "No overlapping regions found.\n"
     ]
    }
   ],
   "source": [
    "def check_overlap(i, geom1, regions):\n",
    "    overlap_pairs = []\n",
    "    for j, geom2 in regions.iterrows():\n",
    "        if i != j and geom1.overlaps(geom2['geometry']):\n",
    "            overlap_pairs.append((i, j))\n",
    "    return overlap_pairs\n",
    "\n",
    "def find_overlapping_regions(regions):\n",
    "    overlap_pairs = []\n",
    "    total_items = len(regions)  # Total number of items to process\n",
    "    progress_interval = 1000  # Print progress every 1000 items\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(check_overlap, i, geom1['geometry'], regions)\n",
    "            for i, geom1 in regions.iterrows()\n",
    "        ]\n",
    "        \n",
    "        for idx, future in enumerate(futures):\n",
    "            result = future.result()\n",
    "            overlap_pairs.extend(result)\n",
    "            \n",
    "            # Print progress every 1000 items\n",
    "            if (idx + 1) % progress_interval == 0 or (idx + 1) == total_items:\n",
    "                print(f\"Processed {idx + 1} out of {total_items} items.\")\n",
    "\n",
    "    return overlap_pairs\n",
    "\n",
    "overlaps = find_overlapping_regions(districts)\n",
    "\n",
    "if overlaps:\n",
    "    print(\"Overlapping regions found:\")\n",
    "    for pair in overlaps:\n",
    "        print(f\"Region {pair[0]} overlaps with Region {pair[1]}\")\n",
    "else:\n",
    "    print(\"No overlapping regions found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea380693-4661-4560-b3cc-49fb82158d80",
   "metadata": {},
   "source": [
    "## Regions must be completely contained by parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e11947f-e288-4111-8a27-b7b90517275b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No containment issues\n"
     ]
    }
   ],
   "source": [
    "def check_individual_containment(children, parents, threshold=0.99) -> list:\n",
    "    containment_issues = []\n",
    "\n",
    "    for i, child in children.iterrows():\n",
    "        parent_region_key = '@'.join(child['region_key'].split('@')[:-1])\n",
    "        parent_region = parents[parents['region_key'] == parent_region_key]\n",
    "        if not parent_region.empty:\n",
    "            parent = parent_region.iloc[0]['geometry']\n",
    "            intersection_area = child['geometry'].intersection(parent).area\n",
    "            intersection_percentage = intersection_area / child['geometry'].area\n",
    "            \n",
    "            if intersection_percentage < threshold or intersection_percentage > 1.01:\n",
    "                containment_issues.append(f'''\n",
    "                    Containment error region key: {child[\"region_key\"]} \n",
    "                    Intersection percentage: {intersection_percentage}\n",
    "                ''')\n",
    "        else:\n",
    "            containment_issues.append(f\"Parent region not found for child region key: {child['region_key']}\")\n",
    "    return containment_issues\n",
    "\n",
    "containment_issues = check_individual_containment(districts, divisions)\n",
    "\n",
    "if len(containment_issues) > 0:\n",
    "    print(f'{len(containment_issues)} containment issues found:')\n",
    "    for issue in containment_issues:\n",
    "        print(issue)\n",
    "else:\n",
    "    print(\"No containment issues\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2462be1b-2a26-4553-9c37-1613578a1590",
   "metadata": {},
   "source": [
    "## Regions must not contain gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00952296-fbad-41ab-a7db-22c6cf108a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No parent gap issues\n"
     ]
    }
   ],
   "source": [
    "containment_issues = check_region_containment(districts, divisions)\n",
    "\n",
    "if len(containment_issues) > 0:\n",
    "    print(f'{len(containment_issues)} containment issues found:')\n",
    "    for issue in containment_issues:\n",
    "        print(issue)\n",
    "else:\n",
    "    print(\"No parent gap issues\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688e9fd2-a914-4787-8867-31dca91e7545",
   "metadata": {},
   "source": [
    "# Upazilas\n",
    "## Region keys must be complete, containing no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "252dde1e-2dc6-4bae-9870-ae8588ef92ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 544 entries, 0 to 543\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   area        544 non-null    float64 \n",
      " 1   upa         544 non-null    object  \n",
      " 2   dis         544 non-null    object  \n",
      " 3   div         544 non-null    object  \n",
      " 4   geometry    544 non-null    geometry\n",
      " 5   region_key  544 non-null    object  \n",
      "dtypes: float64(1), geometry(1), object(4)\n",
      "memory usage: 25.6+ KB\n",
      "\n",
      "\n",
      "area, div, dis, upa, geometry non-null is 544. df length is also 544\n"
     ]
    }
   ],
   "source": [
    "upazilas.info()\n",
    "\n",
    "print('\\n')\n",
    "print('area, div, dis, upa, geometry non-null is 544. df length is also 544')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a194bff1-3a31-4433-ba2b-8778110aa195",
   "metadata": {},
   "source": [
    "## Region keys must be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2731f97-7e78-41b3-89af-d8a8d46cb4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upazila region keys unique\n"
     ]
    }
   ],
   "source": [
    "upa_vc = upazilas['region_key'].value_counts()\n",
    "\n",
    "if len(upa_vc[upa_vc > 1]) == 0:\n",
    "    print('upazila region keys unique')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec36088c-7f90-46dc-8a73-e0bc873d8db4",
   "metadata": {},
   "source": [
    "## Each region (excluding divs) must have a valid parent which it is contained by and labelled by region key as within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "581d4506-61bc-4af4-b6dc-b87ccd749d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of errors: 0\n",
      "No errors found.\n"
     ]
    }
   ],
   "source": [
    "errors = validate_region_parents(upazilas, districts, 'dis')\n",
    "\n",
    "total_errors = sum(len(err_dict['errors']) for err_dict in errors)\n",
    "print(f'Total number of errors: {total_errors}')\n",
    "\n",
    "if total_errors == 0:\n",
    "    print(\"No errors found.\")\n",
    "else:\n",
    "    print(f\"Errors found: {total_errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9b064a-1d21-4cd7-990e-e6e8b619410c",
   "metadata": {},
   "source": [
    "## Regions must not overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eda19d4a-e85c-4811-9434-d51252a64541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 544 out of 544 items.\n",
      "Overlapping regions found:\n",
      "Region 26 overlaps with Region 349\n",
      "Region 349 overlaps with Region 26\n"
     ]
    }
   ],
   "source": [
    "overlaps = find_overlapping_regions(upazilas)\n",
    "\n",
    "if overlaps:\n",
    "    print(\"Overlapping regions found:\")\n",
    "    for pair in overlaps:\n",
    "        print(f\"Region {pair[0]} overlaps with Region {pair[1]}\")\n",
    "else:\n",
    "    print(\"No overlapping regions found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df3f595-017b-4327-8c70-e3bb4b18c9bc",
   "metadata": {},
   "source": [
    "## Regions must be completely contained by parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b486785d-0941-40c0-8b8b-f59f8f856120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No containment issues\n"
     ]
    }
   ],
   "source": [
    "containment_issues = check_individual_containment(upazilas, districts)\n",
    "\n",
    "if len(containment_issues) > 0:\n",
    "    print(f'{len(containment_issues)} containment issues found:')\n",
    "    for issue in containment_issues:\n",
    "        print(issue)\n",
    "else:\n",
    "    print(\"No containment issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bdaade-fd34-4903-b05d-c180794621a3",
   "metadata": {},
   "source": [
    "## Regions must not contain gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c564a74a-6bdd-44f5-b8d9-56d2b4956338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No parent gap issues\n"
     ]
    }
   ],
   "source": [
    "containment_issues = check_region_containment(upazilas, districts)\n",
    "\n",
    "if len(containment_issues) > 0:\n",
    "    print(f'{len(containment_issues)} containment issues found:')\n",
    "    for issue in containment_issues:\n",
    "        print(issue)\n",
    "else:\n",
    "    print(\"No parent gap issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea6f5a6-13b0-4192-823a-e91550277ef1",
   "metadata": {},
   "source": [
    "# Unions\n",
    "## Region keys must be complete, containing no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f16ecc3-6e94-4461-ac02-9c9922736b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 5160 entries, 0 to 5159\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   area        5160 non-null   float64 \n",
      " 1   uni         5160 non-null   object  \n",
      " 2   upa         5160 non-null   object  \n",
      " 3   dis         5160 non-null   object  \n",
      " 4   div         5160 non-null   object  \n",
      " 5   geometry    5160 non-null   geometry\n",
      " 6   region_key  5160 non-null   object  \n",
      "dtypes: float64(1), geometry(1), object(5)\n",
      "memory usage: 282.3+ KB\n",
      "\n",
      "\n",
      "area, div, dis, upa, uni, geometry non-null is 5160. df length is also 5160\n"
     ]
    }
   ],
   "source": [
    "unions.info()\n",
    "\n",
    "print('\\n')\n",
    "print('area, div, dis, upa, uni, geometry non-null is 5160. df length is also 5160')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06913a4e-142d-486e-8315-c1864208d55e",
   "metadata": {},
   "source": [
    "## Region keys must be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c79bcd04-9328-4083-94ef-f07d15442073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "union region keys unique\n",
      "Unions with duplicate region keys: 0\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 5160 entries, 0 to 5159\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   region_key  5160 non-null   object  \n",
      " 1   geometry    5160 non-null   geometry\n",
      " 2   div         5160 non-null   object  \n",
      " 3   dis         5160 non-null   object  \n",
      " 4   upa         5160 non-null   object  \n",
      " 5   uni         5160 non-null   object  \n",
      " 6   area        5160 non-null   float64 \n",
      "dtypes: float64(1), geometry(1), object(5)\n",
      "memory usage: 282.3+ KB\n",
      "None\n",
      "union region keys unique\n"
     ]
    }
   ],
   "source": [
    "# We know unions can be corrected by merging those with same region key\n",
    "# from work done in map-data-fix.ipynb (mouzas are not as simple as some exist in \n",
    "# wrong parent region)\n",
    "uni_vc = unions['region_key'].value_counts()\n",
    "\n",
    "if len(uni_vc[uni_vc > 1]) == 0:\n",
    "    print('union region keys unique')\n",
    "else:\n",
    "    print(f'{len(uni_vc[uni_vc > 1])} not unique')\n",
    "\n",
    "def merge_regions_by_key(unions):\n",
    "    merged_unions = (\n",
    "        unions.groupby('region_key')\n",
    "        .agg({\n",
    "            'geometry': lambda x: unary_union(x),\n",
    "            'div': 'first',\n",
    "            'dis': 'first',\n",
    "            'upa': 'first',\n",
    "            'uni': 'first',\n",
    "            'area': 'sum'\n",
    "        })\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    return merged_unions\n",
    "\n",
    "unions = merge_regions_by_key(unions)\n",
    "unions['region_key'] = unions['div'] + '@' + unions['dis'] + '@' + unions['upa'] + '@' + unions['uni']\n",
    "\n",
    "duplicate_keys = unions['region_key'].value_counts()\n",
    "print('Unions with duplicate region keys:', len(duplicate_keys[duplicate_keys > 1]))\n",
    "\n",
    "print(unions.info())\n",
    "\n",
    "uni_vc = unions['region_key'].value_counts()\n",
    "\n",
    "if len(uni_vc[uni_vc > 1]) == 0:\n",
    "    print('union region keys unique')\n",
    "else:\n",
    "    print(f'{len(uni_vc[uni_vc > 1])} not unique')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35948059-7502-4e1d-8855-8b82d9d3b039",
   "metadata": {},
   "source": [
    "## Each region (excluding divs) must have a valid parent which it is contained by and labelled by region key as within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0c699af-c137-4323-80b3-94f7a7dbb6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of errors: 0\n",
      "No errors found.\n"
     ]
    }
   ],
   "source": [
    "errors = validate_region_parents(unions, upazilas, 'upa')\n",
    "\n",
    "total_errors = sum(len(err_dict['errors']) for err_dict in errors)\n",
    "print(f'Total number of errors: {total_errors}')\n",
    "\n",
    "if total_errors == 0:\n",
    "    print(\"No errors found.\")\n",
    "else:\n",
    "    print(f\"Errors found: {total_errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eb3558-af69-4309-bf2b-ca1b39313e06",
   "metadata": {},
   "source": [
    "## Regions must not overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bf312fd-e03c-4323-a35c-2d771cf507e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 out of 5160 items.\n",
      "Processed 2000 out of 5160 items.\n",
      "Processed 3000 out of 5160 items.\n",
      "Processed 4000 out of 5160 items.\n",
      "Processed 5000 out of 5160 items.\n",
      "Processed 5160 out of 5160 items.\n",
      "Overlapping regions found:\n",
      "Region 4496 overlaps with Region 4523\n",
      "Region 4523 overlaps with Region 4496\n",
      "Region 5021 overlaps with Region 5024\n",
      "Region 5024 overlaps with Region 5021\n"
     ]
    }
   ],
   "source": [
    "overlaps = find_overlapping_regions(unions)\n",
    "\n",
    "if overlaps:\n",
    "    print(\"Overlapping regions found:\")\n",
    "    for pair in overlaps:\n",
    "        print(f\"Region {pair[0]} overlaps with Region {pair[1]}\")\n",
    "else:\n",
    "    print(\"No overlapping regions found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b556a5ca-aefc-4877-bb5f-94e726ccfaba",
   "metadata": {},
   "source": [
    "## Regions must be completely contained by parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3899ba24-8d09-42a6-bda9-275665eb907a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No containment issues\n"
     ]
    }
   ],
   "source": [
    "containment_issues = check_individual_containment(unions, upazilas)\n",
    "\n",
    "if len(containment_issues) > 0:\n",
    "    print(f'{len(containment_issues)} containment issues found:')\n",
    "    for issue in containment_issues:\n",
    "        print(issue)\n",
    "else:\n",
    "    print(\"No containment issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4d3411-abc5-4020-9caa-db3844fcbee4",
   "metadata": {},
   "source": [
    "## Regions must not contain gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1069292-d930-4e45-90e4-a9a81ebb46f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No parent gap issues\n"
     ]
    }
   ],
   "source": [
    "containment_issues = check_region_containment(unions, upazilas)\n",
    "\n",
    "if len(containment_issues) > 0:\n",
    "    print(f'{len(containment_issues)} containment issues found:')\n",
    "    for issue in containment_issues:\n",
    "        print(issue)\n",
    "else:\n",
    "    print(\"No parent gap issues\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ae33b92-8c56-4cc4-9d34-0e94d4646482",
   "metadata": {},
   "source": [
    "# Mouzas\n",
    "\n",
    "Mouza maps include big Dhaka region that needs to be fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0eb91247-8a20-4d58-8c07-2bd5ea062316",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = mouzas.copy()\n",
    "unc = unions.copy()\n",
    "\n",
    "# Drop items with no geometry\n",
    "mc = mc.dropna(subset=['geometry'])\n",
    "\n",
    "# add area to mouca df\n",
    "mc['area'] = mc['geometry'].area\n",
    "\n",
    "mc.set_geometry('geometry', inplace=True)\n",
    "unc.set_geometry('geometry', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a61bf4e-6df5-4a62-b6cb-a70d0c5d2b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 1000 of 58469\n",
      "processing 2000 of 58469\n",
      "processing 3000 of 58469\n",
      "processing 4000 of 58469\n",
      "processing 5000 of 58469\n",
      "processing 6000 of 58469\n",
      "processing 7000 of 58469\n",
      "processing 8000 of 58469\n",
      "processing 9000 of 58469\n",
      "processing 10000 of 58469\n",
      "processing 11000 of 58469\n",
      "processing 12000 of 58469\n",
      "processing 13000 of 58469\n",
      "processing 14000 of 58469\n",
      "processing 15000 of 58469\n",
      "processing 16000 of 58469\n",
      "processing 17000 of 58469\n",
      "processing 18000 of 58469\n",
      "processing 19000 of 58469\n",
      "processing 20000 of 58469\n",
      "processing 21000 of 58469\n",
      "processing 22000 of 58469\n",
      "processing 23000 of 58469\n",
      "processing 24000 of 58469\n",
      "processing 25000 of 58469\n",
      "processing 26000 of 58469\n",
      "processing 27000 of 58469\n",
      "processing 28000 of 58469\n",
      "processing 29000 of 58469\n",
      "processing 30000 of 58469\n",
      "processing 31000 of 58469\n",
      "processing 32000 of 58469\n",
      "processing 33000 of 58469\n",
      "processing 34000 of 58469\n",
      "processing 35000 of 58469\n",
      "processing 36000 of 58469\n",
      "processing 37000 of 58469\n",
      "processing 38000 of 58469\n",
      "processing 39000 of 58469\n",
      "processing 40000 of 58469\n",
      "processing 41000 of 58469\n",
      "processing 42000 of 58469\n",
      "processing 43000 of 58469\n",
      "processing 44000 of 58469\n",
      "processing 45000 of 58469\n",
      "processing 46000 of 58469\n",
      "processing 47000 of 58469\n",
      "processing 48000 of 58469\n",
      "processing 49000 of 58469\n",
      "processing 50000 of 58469\n",
      "processing 51000 of 58469\n",
      "processing 52000 of 58469\n",
      "processing 53000 of 58469\n",
      "processing 54000 of 58469\n",
      "processing 55000 of 58469\n",
      "processing 56000 of 58469\n",
      "processing 57000 of 58469\n",
      "processing 58000 of 58469\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 58499 entries, 0 to 58498\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   area        58499 non-null  float64 \n",
      " 1   div         58438 non-null  object  \n",
      " 2   dis         58441 non-null  object  \n",
      " 3   upa         58300 non-null  object  \n",
      " 4   uni         58267 non-null  object  \n",
      " 5   mou         57559 non-null  object  \n",
      " 6   geometry    58499 non-null  geometry\n",
      " 7   region_key  57351 non-null  object  \n",
      "dtypes: float64(1), geometry(1), object(6)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "mc.set_crs(epsg=32645, inplace=True)\n",
    "unc.set_crs(epsg=32645, inplace=True)\n",
    "\n",
    "# List to collect new rows for mouzas split by unions\n",
    "new_mouzas = []\n",
    "# List to collect indexes of mouzas to drop\n",
    "indexes_to_drop = []\n",
    "\n",
    "# Loop through each mouza in mc\n",
    "count = 0\n",
    "for i, mouza in mc.iterrows():\n",
    "    count += 1\n",
    "    if count % 1000 == 0:\n",
    "        print(f'processing {count} of {len(mc)}')\n",
    "    # Find unions contained within the current mouza\n",
    "    unions_within_mouza = unc[unc['geometry'].centroid.within(mouza['geometry'])].copy()\n",
    "    unions_within_mouza = unions_within_mouza.set_geometry('geometry')\n",
    "    unions_within_mouza.set_crs(epsg=32645, inplace=True)\n",
    "\n",
    "    # If there are multiple unions within the mouza\n",
    "    if len(unions_within_mouza) > 0:\n",
    "        # Split the mouza by the unions\n",
    "        for j, union in unions_within_mouza.iterrows():\n",
    "            # Create a new 'mouza' geometry for each union\n",
    "            new_mouza = mouza.copy()\n",
    "            new_mouza['geometry'] = mouza['geometry'].intersection(union['geometry'])\n",
    "            new_mouza['mou'] = union['uni']  # Set 'mou' to the value of 'uni'\n",
    "            new_mouzas.append(new_mouza)\n",
    "\n",
    "        # Add the index to the list to drop the original overly large mouza\n",
    "        indexes_to_drop.append(i)\n",
    "\n",
    "# Convert the list of new mouzas to a GeoDataFrame and concatenate it back to mc\n",
    "new_mouzas_df = gpd.GeoDataFrame(new_mouzas, crs=mc.crs)\n",
    "mc = pd.concat([mc, new_mouzas_df], ignore_index=True)\n",
    "\n",
    "# Drop all original overly large mouzas at once\n",
    "mc = mc.drop(indexes_to_drop).reset_index(drop=True)\n",
    "\n",
    "# Reset the region_key for all rows\n",
    "mc['region_key'] = mc['div'] + '@' + mc['dis'] + '@' + mc['upa'] + '@' + mc['uni'] + '@' + mc['mou']\n",
    "\n",
    "# Output the updated DataFrame info\n",
    "mc.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5223860-c8cd-43d0-956e-696f5f4e39e9",
   "metadata": {},
   "source": [
    "## Region keys must be complete, containing no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d1edaa-f394-4d0f-8ab2-f5841cdd9c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unc['centroid'] = unc['geometry'].centroid\n",
    "\n",
    "# Fill missing values for 'div', 'dis', 'upa', and 'uni'\n",
    "count = 0\n",
    "for i, m in mc.iterrows():\n",
    "    count += 1\n",
    "\n",
    "    if count % 500 == 0:\n",
    "        print(f\"Processing row {count} / {len(mc)}\")\n",
    "    parent, _ = find_best_parent(m['geometry'], unc)\n",
    "    if parent is None:\n",
    "        # if mouza is not within a union, add its geometry\n",
    "        # to the nearest union by centroid\n",
    "        m_centroid = m['geometry'].centroid\n",
    "        unc['distance_to_geometry'] = unc['centroid'].apply(lambda x: m_centroid.distance(x))\n",
    "        nearest_union = unc.sort_values(by='distance_to_geometry').head(1).index[0]\n",
    "\n",
    "        # expand union to include parentless mouza\n",
    "        unc.at[nearest_union, 'geometry'] = unc.loc[nearest_union, 'geometry'].union(m['geometry'])\n",
    "        parent, _ = find_best_parent(m['geometry'], unc)\n",
    "\n",
    "        if parent is None:\n",
    "            print(f'still no parent for {i} after merging geometry to nearest union')\n",
    "\n",
    "    mc.at[i, 'div'] = parent['div']\n",
    "    mc.at[i, 'dis'] = parent['dis']\n",
    "    mc.at[i, 'upa'] = parent['upa']\n",
    "    mc.at[i, 'uni'] = parent['uni']\n",
    "\n",
    "print('step 1')\n",
    "# List to store new merged mouzas\n",
    "rows_to_add = []\n",
    "rows_to_remove = []\n",
    "\n",
    "# Handle merging of mouzas within the same union\n",
    "for upa_uni, union_group in mc.groupby(['upa', 'uni']):\n",
    "    mouza_missing = union_group[union_group['mou'].isnull()]\n",
    "\n",
    "    if len(mouza_missing) == 0:\n",
    "        continue\n",
    "\n",
    "    if len(mouza_missing) == 1:\n",
    "        # If there is only one mouza missing, set its 'mou' to the 'uni' value\n",
    "        mouza_index = mouza_missing.index[0]\n",
    "        mc.at[mouza_index, 'mou'] = mc.loc[mouza_index, 'uni']\n",
    "        continue\n",
    "    \n",
    "    # Merge geometries of all mouza_missing into a single polygon\n",
    "    merged_geometry = mouza_missing.geometry.union_all()\n",
    "    \n",
    "    # Create a new row for the merged mouza\n",
    "    new_row = {\n",
    "        'div': mouza_missing['div'].iloc[0],\n",
    "        'dis': mouza_missing['dis'].iloc[0],\n",
    "        'upa': mouza_missing['upa'].iloc[0],\n",
    "        'uni': mouza_missing['uni'].iloc[0],\n",
    "        'mou': mouza_missing['uni'].iloc[0],\n",
    "        'geometry': merged_geometry\n",
    "    }\n",
    "    \n",
    "    # Append new row to rows_to_add\n",
    "    rows_to_add.append(new_row)\n",
    "    \n",
    "    # Collect the mouzas to be removed\n",
    "    rows_to_remove.extend(mouza_missing.index.tolist())\n",
    "\n",
    "print('step 2')\n",
    "\n",
    "# Remove all rows that were merged\n",
    "mc = mc.drop(rows_to_remove)\n",
    "\n",
    "# Convert rows_to_add into a DataFrame and append to the existing DataFrame\n",
    "merged_mouzas_df = pd.DataFrame(rows_to_add)\n",
    "mc = pd.concat([mc, merged_mouzas_df], ignore_index=True)\n",
    "\n",
    "# Update region_key column\n",
    "mc['region_key'] = mc['div'] + '@' + mc['dis'] + '@' + mc['upa'] + '@' + mc['uni'] + '@' + mc['mou']\n",
    "\n",
    "# Merge rows with duplicate region_key\n",
    "rows_to_add = []\n",
    "rows_to_remove = []\n",
    "\n",
    "# Identify and merge rows with duplicate region_key\n",
    "for region_key, group in mc.groupby('region_key'):\n",
    "    if len(group) > 1:\n",
    "        # Merge geometries of duplicates\n",
    "        merged_geometry = group.geometry.union_all()\n",
    "\n",
    "        # Create new row for merged region\n",
    "        new_row = {\n",
    "            'div': group['div'].iloc[0],\n",
    "            'dis': group['dis'].iloc[0],\n",
    "            'upa': group['upa'].iloc[0],\n",
    "            'uni': group['uni'].iloc[0],\n",
    "            'mou': group['mou'].iloc[0],\n",
    "            'geometry': merged_geometry,\n",
    "            'region_key': region_key\n",
    "        }\n",
    "\n",
    "        # Append new row to rows_to_add\n",
    "        rows_to_add.append(new_row)\n",
    "\n",
    "        # Collect the original rows to be removed\n",
    "        rows_to_remove.extend(group.index.tolist())\n",
    "\n",
    "# Remove duplicate rows\n",
    "mc = mc.drop(rows_to_remove)\n",
    "\n",
    "# Add merged rows\n",
    "merged_regions_df = pd.DataFrame(rows_to_add)\n",
    "mc = pd.concat([mc, merged_regions_df], ignore_index=True)\n",
    "\n",
    "# Update region_key column\n",
    "mc['region_key'] = mc['div'] + '@' + mc['dis'] + '@' + mc['upa'] + '@' + mc['uni'] + '@' + mc['mou']\n",
    "# Output the resulting DataFrame info\n",
    "mc.info()\n",
    "\n",
    "# Check if there are still any mouzas without names\n",
    "unnamed_mouzas = mc[mc['mou'].isnull()]\n",
    "print(f'Number of unnamed mouzas: {len(unnamed_mouzas)}')\n",
    "\n",
    "if len(unnamed_mouzas) > 0:\n",
    "    print(unnamed_mouzas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7413ff2-61db-4f79-bcf9-a66b92e06676",
   "metadata": {},
   "source": [
    "## Region keys must be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a5e0e-b060-4c11-8d39-e5232ba86bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mou_vc = mc['region_key'].value_counts()\n",
    "\n",
    "if len(mou_vc[mou_vc > 1]) == 0:\n",
    "    print('mouza region keys unique')\n",
    "else:\n",
    "    print(f'{len(mou_vc[mou_vc > 1])} not unique')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973b5019-b695-4b56-8f5d-8f362368c75b",
   "metadata": {},
   "source": [
    "## Each region (excluding divs) must have a valid parent which it is contained by and labelled by region key as within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6a3d7a-d2ef-4576-ace5-b6855508944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = validate_region_parents(mc, unc, 'uni')\n",
    "\n",
    "total_errors = sum(len(err_dict['errors']) for err_dict in errors)\n",
    "print(f'Total number of errors: {total_errors}')\n",
    "\n",
    "if total_errors == 0:\n",
    "    print(\"No errors found.\")\n",
    "else:\n",
    "    print(f\"Errors found: {total_errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf7b90c-8cc6-4b20-93bb-d49f26811f26",
   "metadata": {},
   "source": [
    "## Regions must not overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d57f18-b94c-4d67-86e7-f705737a94dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_chunks = 128\n",
    "chunks = [[] for _ in range(num_chunks)]\n",
    "for i, row in mc.iterrows():\n",
    "    chunk_index = i % num_chunks\n",
    "    chunks[chunk_index].append(row)\n",
    "\n",
    "chunks = [pd.DataFrame(chunk) for chunk in chunks]\n",
    "\n",
    "overlaps = []\n",
    "for i in range(len(chunks)):\n",
    "    overlaps.extend(find_overlapping_regions(chunks[i]))\n",
    "\n",
    "if overlaps:\n",
    "    print(\"Overlapping regions found:\")\n",
    "    for pair in overlaps:\n",
    "        print(f\"Region {pair[0]} overlaps with Region {pair[1]}\")\n",
    "else:\n",
    "    print(\"No overlapping regions found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0264c623-1556-409b-824b-75c2c0b82c75",
   "metadata": {},
   "source": [
    "## Regions must be completely contained by parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b799dba9-0957-421e-b0a1-2162092e21d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "containment_issues = check_individual_containment(mc, unc, 0.9)\n",
    "\n",
    "if len(containment_issues) > 0:\n",
    "    print(f'{len(containment_issues)} containment issues found:')\n",
    "    \n",
    "    for issue in containment_issues:\n",
    "        print(issue)\n",
    "        \n",
    "        # Get labelled parent for the current issue\n",
    "        mouza_region_key = issue.split('\\n')[1].split(':')[1].strip()\n",
    "        mouza = mc[mc['region_key'] == mouza_region_key].iloc[0]\n",
    "        \n",
    "        labelled_parent = get_labelled_parent(\n",
    "            mouza,\n",
    "            unc,\n",
    "        )\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "        gpd.GeoDataFrame(geometry=[labelled_parent['geometry']]).plot(ax=ax, linewidth=2, edgecolor='red', facecolor='none', alpha=0.5)\n",
    "        gpd.GeoDataFrame(geometry=[mouza['geometry']]).plot(ax=ax, linewidth=1, edgecolor='blue', facecolor='none', alpha=0.5)\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        print('================================')\n",
    "\n",
    "else:\n",
    "    print(\"No containment issues\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a252e9da-ba86-41cf-942e-8a015e04bcbd",
   "metadata": {},
   "source": [
    "## Regions must not contain gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e9dc5b-b85d-4a74-b28a-5ea9cc2c0c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "containment_issues = check_region_containment(mc, unions)\n",
    "\n",
    "if len(containment_issues) > 0:\n",
    "    print(f'{len(containment_issues)} containment issues found:')\n",
    "    for issue in containment_issues:\n",
    "        print(issue)\n",
    "else:\n",
    "    print(\"No parent gap issues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bbef01-d13b-4900-82ce-436f079273aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "divisions.to_file('div.geojson', driver='GeoJSON')\n",
    "districts.to_file('dis.geojson', driver='GeoJSON')\n",
    "upazilas.to_file('upa.geojson', driver='GeoJSON')\n",
    "unc.drop(columns=['centroid']).to_file('uni.geojson', driver='GeoJSON')\n",
    "mc.to_file('mou.geojson', driver='GeoJSON')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
