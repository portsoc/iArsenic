{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e06e1357-aa10-476d-8c62-696dcd7ac915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.ops import unary_union\n",
    "from shapely.affinity import scale\n",
    "from shapely.geometry import Polygon\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c429f1-ee54-4f25-86f5-728df4bb52db",
   "metadata": {},
   "outputs": [],
   "source": [
    "divisions = gpd.read_file('../../preprocessing/geodata/maps/dist/div/div-c005-s020-vw-pr.geojson').to_crs(epsg=32645)\n",
    "districts = gpd.read_file('../../preprocessing/geodata/maps/dist/dis/dis-c005-s020-vw-pr.geojson').to_crs(epsg=32645)\n",
    "upazilas = gpd.read_file('../../preprocessing/geodata/maps/dist/upa/upa-c005-s020-vw-pr.geojson').to_crs(epsg=32645)\n",
    "unions = gpd.read_file('../../preprocessing/geodata/maps/dist/uni/uni-c005-s020-vw-pr.geojson').to_crs(epsg=32645)\n",
    "mouzas = gpd.read_file('../../preprocessing/geodata/maps/dist/mou/mou-c005-s020-vw-pr.geojson').to_crs(epsg=32645)\n",
    "\n",
    "divisions['region_key'] = divisions['div']\n",
    "districts['region_key'] = districts['div'] + '@' + districts['dis']\n",
    "upazilas['region_key'] = upazilas['div'] + '@' + upazilas['dis'] + '@' + upazilas['upa']\n",
    "unions['region_key'] = unions['div'] + '@' + unions['dis'] + '@' + unions['upa'] + '@' + unions['uni']\n",
    "mouzas['region_key'] = mouzas['div'] + '@' + mouzas['dis'] + '@' + mouzas['upa'] + '@' + mouzas['uni'] + '@' + mouzas['mou']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4ea0aa-1584-46cd-b094-f6d15209c9bd",
   "metadata": {},
   "source": [
    "# Rules for datastructure\n",
    "1. Region keys must be complete, containing no null values\n",
    "2. Region keys must be unique\n",
    "3. Each region (excluding divs) must have a valid parent which it is contained by and labelled by region key as within\n",
    "4. Regions must not overlap\n",
    "5. Regions must be completely contained by parent\n",
    "6. Regions must not contain gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e063ef54-8f19-4ad4-a83f-5a0c75f3a504",
   "metadata": {},
   "source": [
    "# Divisions\n",
    "## Region keys must be complete, containing no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acd5e32b-c7c8-4f89-ae98-b7c444560f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   area        8 non-null      float64 \n",
      " 1   div         8 non-null      object  \n",
      " 2   geometry    8 non-null      geometry\n",
      " 3   region_key  8 non-null      object  \n",
      "dtypes: float64(1), geometry(1), object(2)\n",
      "memory usage: 388.0+ bytes\n",
      "\n",
      "\n",
      "area, div, geometry non-null is 8. df length is also 8\n"
     ]
    }
   ],
   "source": [
    "divisions.info()\n",
    "\n",
    "print('\\n')\n",
    "print('area, div, geometry non-null is 8. df length is also 8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaf2423-f97a-4cd5-9a07-6529bf083873",
   "metadata": {},
   "source": [
    "## Region keys must be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c450119b-4950-4374-890b-9bab0616808c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divion region keys unique\n"
     ]
    }
   ],
   "source": [
    "div_vc = divisions['region_key'].value_counts()\n",
    "\n",
    "if len(div_vc[div_vc > 1]) == 0:\n",
    "    print('divion region keys unique')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c94d7e-422f-4778-ad12-69e6cef0a038",
   "metadata": {},
   "source": [
    "## Each region (excluding divs) must have a valid parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30623641-6a54-4300-9685-7d3f3ecf23a1",
   "metadata": {},
   "source": [
    "divs do not require parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed68a8d-d3bf-4ad1-8476-887a29525359",
   "metadata": {},
   "source": [
    "## Regions must not overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02353569-cec0-4217-9b74-1d4c9689cace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No overlapping regions found.\n"
     ]
    }
   ],
   "source": [
    "overlap_pairs = []\n",
    "\n",
    "for i, geom1 in divisions.iterrows():\n",
    "    for j, geom2 in divisions.iterrows():\n",
    "        if i != j:\n",
    "            if geom1['geometry'].overlaps(geom2['geometry']):\n",
    "                overlap_pairs.append((i, j))\n",
    "\n",
    "# Report the results\n",
    "if overlap_pairs:\n",
    "    print(\"Overlapping regions found:\")\n",
    "    for pair in overlap_pairs:\n",
    "        print(f\"Region {pair[0]} overlaps with Region {pair[1]}\")\n",
    "else:\n",
    "    print(\"No overlapping regions found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d0c66b-af6b-4a45-9f78-c49252fe9a46",
   "metadata": {},
   "source": [
    "## Regions must be completely contained by parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f7a1cc-5f0e-4bfd-acef-68ca86b863ab",
   "metadata": {},
   "source": [
    "divs do not require parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b8fc9c-97fa-4feb-82d6-468777d47ce2",
   "metadata": {},
   "source": [
    "## Regions must not contain gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50f5b28d-35ef-4f2b-b79f-a656437f9c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No parent gap issues\n"
     ]
    }
   ],
   "source": [
    "def check_region_containment(parents, children) -> list:\n",
    "    containment_issues = []\n",
    "\n",
    "    for i, parent in parents.iterrows():\n",
    "        parent_region_key = parent['region_key']\n",
    "        child_regions = children[children['region_key'].str.contains(parent_region_key, regex=False)]\n",
    "\n",
    "        if child_regions.empty:\n",
    "            continue\n",
    "\n",
    "        parent_geometry = parent['geometry']\n",
    "        parent_area = parent_geometry.area\n",
    "\n",
    "        total_child_area = sum(child['geometry'].area for _, child in child_regions.iterrows())\n",
    "        total_intersection_area = sum(child['geometry'].intersection(parent_geometry).area for _, child in child_regions.iterrows())\n",
    "        \n",
    "        if total_child_area < 0.99 * parent_area or total_child_area > 1.01 * parent_area:\n",
    "            containment_issues.append(f'''\n",
    "                Area mismatch for parent region key: {parent_region_key} \n",
    "                Total child area: {total_child_area}, Parent area: {parent_area}\n",
    "            ''')\n",
    "        \n",
    "        if total_intersection_area < 0.99 * parent_area or total_intersection_area > 1.01 * parent_area:\n",
    "            containment_issues.append(f'''\n",
    "                Containment error for parent region key: {parent_region_key} \n",
    "                Total intersection area: {total_intersection_area}, Parent area: {parent_area}\n",
    "            ''')\n",
    "\n",
    "    return containment_issues\n",
    "\n",
    "containment_issues = check_region_containment(divisions, districts)\n",
    "\n",
    "if len(containment_issues) > 0:\n",
    "    print(f'{len(containment_issues)} containment issues found:')\n",
    "    for issue in containment_issues:\n",
    "        print(issue)\n",
    "else:\n",
    "    print(\"No parent gap issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a429691-f84e-40a7-98a0-779ad840fad7",
   "metadata": {},
   "source": [
    "# Districts\n",
    "## Region keys must be complete, containing no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24bd8823-1854-4c54-8451-6648012f29be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 64 entries, 0 to 63\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   area        64 non-null     float64 \n",
      " 1   dis         64 non-null     object  \n",
      " 2   div         64 non-null     object  \n",
      " 3   geometry    64 non-null     geometry\n",
      " 4   region_key  64 non-null     object  \n",
      "dtypes: float64(1), geometry(1), object(3)\n",
      "memory usage: 2.6+ KB\n",
      "\n",
      "\n",
      "area, div, dis, geometry non-null is 64. df length is also 64\n"
     ]
    }
   ],
   "source": [
    "districts.info()\n",
    "\n",
    "print('\\n')\n",
    "print('area, div, dis, geometry non-null is 64. df length is also 64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbc2f95-fd3e-4fa7-9d6d-bebe4dcf7f8b",
   "metadata": {},
   "source": [
    "## Region keys must be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4682b862-7d5e-4aad-b8a6-60d8f9409bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "district region keys unique\n"
     ]
    }
   ],
   "source": [
    "dis_vc = districts['region_key'].value_counts()\n",
    "\n",
    "if len(dis_vc[dis_vc > 1]) == 0:\n",
    "    print('district region keys unique')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2743a81e-35ae-40a8-a42a-6fc142b1ea7a",
   "metadata": {},
   "source": [
    "## Each region (excluding divs) must have a valid parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7883ef6c-f952-4b6f-9fda-7accf31466a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of errors: 0\n",
      "No errors found.\n"
     ]
    }
   ],
   "source": [
    "def find_best_parent(child_geometry, potential_parents):\n",
    "    best_parent = None\n",
    "    max_intersection_area = 0\n",
    "    child_area = child_geometry.area\n",
    "\n",
    "    for idx, parent_row in potential_parents.iterrows():\n",
    "        parent_geometry = parent_row['geometry']\n",
    "        \n",
    "        intersection = child_geometry.intersection(parent_geometry)\n",
    "        intersection_area = intersection.area\n",
    "        \n",
    "        if intersection_area > max_intersection_area:\n",
    "            max_intersection_area = intersection_area\n",
    "            best_parent = parent_row\n",
    "    \n",
    "    intersection_percentage = max_intersection_area / child_area if child_area > 0 else 0\n",
    "    return best_parent, intersection_percentage\n",
    "\n",
    "def get_labelled_parent(child_region, divisions):\n",
    "    region_parent_key = '@'.join(child_region['region_key'].split('@')[:-1])\n",
    "    labelled_parent = divisions[divisions['region_key'] == region_parent_key]\n",
    "    \n",
    "    if len(labelled_parent) == 1:\n",
    "        return labelled_parent.iloc[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def validate_region_parents(regions, parent_regions, parent_level):\n",
    "    count = 0\n",
    "    errors = []\n",
    "\n",
    "    pps = {\n",
    "        'div': divisions,\n",
    "        'dis': districts,\n",
    "        'upa': upazilas,\n",
    "        'uni': unions,\n",
    "        'mou': mouzas,\n",
    "    }\n",
    "    \n",
    "    for i, row1 in regions.iterrows():\n",
    "        err_dict = { 'region': row1, 'errors': [] }\n",
    "        count += 1\n",
    "\n",
    "        potential_parents = parent_regions[parent_regions[parent_level] == row1[parent_level]]\n",
    "\n",
    "        labelled_parent = None\n",
    "        if len(potential_parents) == 0:\n",
    "            print(f\"Cannot find regions labelled parent region {i}\")\n",
    "\n",
    "            potential_parents = pps[parent_level]\n",
    "        else:\n",
    "            labelled_parent = get_labelled_parent(row1, pps[parent_level])\n",
    "    \n",
    "        best_parent, max_area = find_best_parent(row1['geometry'], potential_parents)\n",
    "    \n",
    "        if best_parent is None or (labelled_parent is not None and best_parent['region_key'] != labelled_parent['region_key']):\n",
    "            if best_parent is None:\n",
    "                err_dict['errors'].append('No geographic parent found')\n",
    "                print('No geographic parent found')\n",
    "    \n",
    "            if labelled_parent is not None and best_parent['region_key'] != labelled_parent['region_key']:\n",
    "                err_dict['errors'].append(f\"Best parent region key ({best_parent['region_key']}) does not match labelled parent region key ({labelled_parent['region_key']})\")\n",
    "                print(f\"Best parent region key: {best_parent['region_key']}\")\n",
    "                print(f\"Labelled parent region key: {labelled_parent['region_key']}\")\n",
    "                \n",
    "            fig, ax = plt.subplots()\n",
    "            \n",
    "            if best_parent is not None:\n",
    "                gpd.GeoDataFrame(geometry=[best_parent['geometry']]).plot(ax=ax, linewidth=2, edgecolor='green', facecolor='none', alpha=0.5, label='Geographic Parent')\n",
    "    \n",
    "            if labelled_parent is not None:\n",
    "                gpd.GeoDataFrame(geometry=[labelled_parent['geometry']]).plot(ax=ax, linewidth=2, edgecolor='red', facecolor='none', alpha=0.5, label='Labelled Parent')\n",
    "            \n",
    "            gpd.GeoDataFrame(geometry=[row1['geometry']]).plot(ax=ax, linewidth=2, edgecolor='blue', facecolor='none', alpha=0.5, label='Child')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "    \n",
    "        errors.append(err_dict)\n",
    "    return errors\n",
    "\n",
    "errors = validate_region_parents(districts, divisions, 'div')\n",
    "\n",
    "total_errors = sum(len(err_dict['errors']) for err_dict in errors)\n",
    "print(f'Total number of errors: {total_errors}')\n",
    "\n",
    "if total_errors == 0:\n",
    "    print(\"No errors found.\")\n",
    "else:\n",
    "    print(f\"Errors found: {total_errors}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d481a2d7-2b48-4193-881e-cd4c7bd61ee2",
   "metadata": {},
   "source": [
    "## Regions must not overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adc14bca-436b-4073-9886-7e5acd97aee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 64 out of 64 items.\n",
      "No overlapping regions found.\n"
     ]
    }
   ],
   "source": [
    "def check_overlap(i, geom1, regions):\n",
    "    overlap_pairs = []\n",
    "    for j, geom2 in regions.iterrows():\n",
    "        if i != j and geom1.overlaps(geom2['geometry']):\n",
    "            overlap_pairs.append((i, j))\n",
    "    return overlap_pairs\n",
    "\n",
    "def find_overlapping_regions(regions):\n",
    "    overlap_pairs = []\n",
    "    total_items = len(regions)  # Total number of items to process\n",
    "    progress_interval = 1000  # Print progress every 1000 items\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(check_overlap, i, geom1['geometry'], regions)\n",
    "            for i, geom1 in regions.iterrows()\n",
    "        ]\n",
    "        \n",
    "        for idx, future in enumerate(futures):\n",
    "            result = future.result()\n",
    "            overlap_pairs.extend(result)\n",
    "            \n",
    "            # Print progress every 1000 items\n",
    "            if (idx + 1) % progress_interval == 0 or (idx + 1) == total_items:\n",
    "                print(f\"Processed {idx + 1} out of {total_items} items.\")\n",
    "\n",
    "    return overlap_pairs\n",
    "\n",
    "overlaps = find_overlapping_regions(districts)\n",
    "\n",
    "if overlaps:\n",
    "    print(\"Overlapping regions found:\")\n",
    "    for pair in overlaps:\n",
    "        print(f\"Region {pair[0]} overlaps with Region {pair[1]}\")\n",
    "else:\n",
    "    print(\"No overlapping regions found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea380693-4661-4560-b3cc-49fb82158d80",
   "metadata": {},
   "source": [
    "## Regions must be completely contained by parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e11947f-e288-4111-8a27-b7b90517275b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No containment issues\n"
     ]
    }
   ],
   "source": [
    "def check_individual_containment(children, parents, threshold=0.99) -> list:\n",
    "    containment_issues = []\n",
    "\n",
    "    for i, child in children.iterrows():\n",
    "        parent_region_key = '@'.join(child['region_key'].split('@')[:-1])\n",
    "        parent_region = parents[parents['region_key'] == parent_region_key]\n",
    "        if not parent_region.empty:\n",
    "            parent = parent_region.iloc[0]['geometry']\n",
    "            intersection_area = child['geometry'].intersection(parent).area\n",
    "            intersection_percentage = intersection_area / child['geometry'].area\n",
    "            \n",
    "            if intersection_percentage < threshold or intersection_percentage > 1.01:\n",
    "                containment_issues.append(f'''\n",
    "                    Containment error region key: {child[\"region_key\"]} \n",
    "                    Intersection percentage: {intersection_percentage}\n",
    "                ''')\n",
    "        else:\n",
    "            containment_issues.append(f\"Parent region not found for child region key: {child['region_key']}\")\n",
    "    return containment_issues\n",
    "\n",
    "containment_issues = check_individual_containment(districts, divisions)\n",
    "\n",
    "if len(containment_issues) > 0:\n",
    "    print(f'{len(containment_issues)} containment issues found:')\n",
    "    for issue in containment_issues:\n",
    "        print(issue)\n",
    "else:\n",
    "    print(\"No containment issues\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2462be1b-2a26-4553-9c37-1613578a1590",
   "metadata": {},
   "source": [
    "## Regions must not contain gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00952296-fbad-41ab-a7db-22c6cf108a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No parent gap issues\n"
     ]
    }
   ],
   "source": [
    "containment_issues = check_region_containment(districts, divisions)\n",
    "\n",
    "if len(containment_issues) > 0:\n",
    "    print(f'{len(containment_issues)} containment issues found:')\n",
    "    for issue in containment_issues:\n",
    "        print(issue)\n",
    "else:\n",
    "    print(\"No parent gap issues\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688e9fd2-a914-4787-8867-31dca91e7545",
   "metadata": {},
   "source": [
    "# Upazilas\n",
    "## Region keys must be complete, containing no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "252dde1e-2dc6-4bae-9870-ae8588ef92ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 544 entries, 0 to 543\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   area        544 non-null    float64 \n",
      " 1   upa         544 non-null    object  \n",
      " 2   dis         544 non-null    object  \n",
      " 3   div         544 non-null    object  \n",
      " 4   geometry    544 non-null    geometry\n",
      " 5   region_key  544 non-null    object  \n",
      "dtypes: float64(1), geometry(1), object(4)\n",
      "memory usage: 25.6+ KB\n",
      "\n",
      "\n",
      "area, div, dis, upa, geometry non-null is 544. df length is also 544\n"
     ]
    }
   ],
   "source": [
    "upazilas.info()\n",
    "\n",
    "print('\\n')\n",
    "print('area, div, dis, upa, geometry non-null is 544. df length is also 544')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a194bff1-3a31-4433-ba2b-8778110aa195",
   "metadata": {},
   "source": [
    "## Region keys must be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2731f97-7e78-41b3-89af-d8a8d46cb4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upazila region keys unique\n"
     ]
    }
   ],
   "source": [
    "upa_vc = upazilas['region_key'].value_counts()\n",
    "\n",
    "if len(upa_vc[upa_vc > 1]) == 0:\n",
    "    print('upazila region keys unique')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec36088c-7f90-46dc-8a73-e0bc873d8db4",
   "metadata": {},
   "source": [
    "## Each region (excluding divs) must have a valid parent which it is contained by and labelled by region key as within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "581d4506-61bc-4af4-b6dc-b87ccd749d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of errors: 0\n",
      "No errors found.\n"
     ]
    }
   ],
   "source": [
    "errors = validate_region_parents(upazilas, districts, 'dis')\n",
    "\n",
    "total_errors = sum(len(err_dict['errors']) for err_dict in errors)\n",
    "print(f'Total number of errors: {total_errors}')\n",
    "\n",
    "if total_errors == 0:\n",
    "    print(\"No errors found.\")\n",
    "else:\n",
    "    print(f\"Errors found: {total_errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9b064a-1d21-4cd7-990e-e6e8b619410c",
   "metadata": {},
   "source": [
    "## Regions must not overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eda19d4a-e85c-4811-9434-d51252a64541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 544 out of 544 items.\n",
      "No overlapping regions found.\n"
     ]
    }
   ],
   "source": [
    "overlaps = find_overlapping_regions(upazilas)\n",
    "\n",
    "if overlaps:\n",
    "    print(\"Overlapping regions found:\")\n",
    "    for pair in overlaps:\n",
    "        print(f\"Region {pair[0]} overlaps with Region {pair[1]}\")\n",
    "else:\n",
    "    print(\"No overlapping regions found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df3f595-017b-4327-8c70-e3bb4b18c9bc",
   "metadata": {},
   "source": [
    "## Regions must be completely contained by parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b486785d-0941-40c0-8b8b-f59f8f856120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No containment issues\n"
     ]
    }
   ],
   "source": [
    "containment_issues = check_individual_containment(upazilas, districts)\n",
    "\n",
    "if len(containment_issues) > 0:\n",
    "    print(f'{len(containment_issues)} containment issues found:')\n",
    "    for issue in containment_issues:\n",
    "        print(issue)\n",
    "else:\n",
    "    print(\"No containment issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bdaade-fd34-4903-b05d-c180794621a3",
   "metadata": {},
   "source": [
    "## Regions must not contain gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c564a74a-6bdd-44f5-b8d9-56d2b4956338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No parent gap issues\n"
     ]
    }
   ],
   "source": [
    "containment_issues = check_region_containment(upazilas, districts)\n",
    "\n",
    "if len(containment_issues) > 0:\n",
    "    print(f'{len(containment_issues)} containment issues found:')\n",
    "    for issue in containment_issues:\n",
    "        print(issue)\n",
    "else:\n",
    "    print(\"No parent gap issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea6f5a6-13b0-4192-823a-e91550277ef1",
   "metadata": {},
   "source": [
    "# Unions\n",
    "## Region keys must be complete, containing no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f16ecc3-6e94-4461-ac02-9c9922736b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 5160 entries, 0 to 5159\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   area        5160 non-null   float64 \n",
      " 1   uni         5160 non-null   object  \n",
      " 2   upa         5160 non-null   object  \n",
      " 3   dis         5160 non-null   object  \n",
      " 4   div         5160 non-null   object  \n",
      " 5   geometry    5160 non-null   geometry\n",
      " 6   region_key  5160 non-null   object  \n",
      "dtypes: float64(1), geometry(1), object(5)\n",
      "memory usage: 282.3+ KB\n",
      "\n",
      "\n",
      "area, div, dis, upa, uni, geometry non-null is 5160. df length is also 5160\n"
     ]
    }
   ],
   "source": [
    "unions.info()\n",
    "\n",
    "print('\\n')\n",
    "print('area, div, dis, upa, uni, geometry non-null is 5160. df length is also 5160')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06913a4e-142d-486e-8315-c1864208d55e",
   "metadata": {},
   "source": [
    "## Region keys must be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c79bcd04-9328-4083-94ef-f07d15442073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "union region keys unique\n",
      "Unions with duplicate region keys: 0\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 5160 entries, 0 to 5159\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   region_key  5160 non-null   object  \n",
      " 1   geometry    5160 non-null   geometry\n",
      " 2   div         5160 non-null   object  \n",
      " 3   dis         5160 non-null   object  \n",
      " 4   upa         5160 non-null   object  \n",
      " 5   uni         5160 non-null   object  \n",
      " 6   area        5160 non-null   float64 \n",
      "dtypes: float64(1), geometry(1), object(5)\n",
      "memory usage: 282.3+ KB\n",
      "None\n",
      "union region keys unique\n"
     ]
    }
   ],
   "source": [
    "# We know unions can be corrected by merging those with same region key\n",
    "# from work done in map-data-fix.ipynb (mouzas are not as simple as some exist in \n",
    "# wrong parent region)\n",
    "uni_vc = unions['region_key'].value_counts()\n",
    "\n",
    "if len(uni_vc[uni_vc > 1]) == 0:\n",
    "    print('union region keys unique')\n",
    "else:\n",
    "    print(f'{len(uni_vc[uni_vc > 1])} not unique')\n",
    "\n",
    "def merge_regions_by_key(unions):\n",
    "    merged_unions = (\n",
    "        unions.groupby('region_key')\n",
    "        .agg({\n",
    "            'geometry': lambda x: unary_union(x),\n",
    "            'div': 'first',\n",
    "            'dis': 'first',\n",
    "            'upa': 'first',\n",
    "            'uni': 'first',\n",
    "            'area': 'sum'\n",
    "        })\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    return merged_unions\n",
    "\n",
    "unions = merge_regions_by_key(unions)\n",
    "unions['region_key'] = unions['div'] + '@' + unions['dis'] + '@' + unions['upa'] + '@' + unions['uni']\n",
    "\n",
    "duplicate_keys = unions['region_key'].value_counts()\n",
    "print('Unions with duplicate region keys:', len(duplicate_keys[duplicate_keys > 1]))\n",
    "\n",
    "print(unions.info())\n",
    "\n",
    "uni_vc = unions['region_key'].value_counts()\n",
    "\n",
    "if len(uni_vc[uni_vc > 1]) == 0:\n",
    "    print('union region keys unique')\n",
    "else:\n",
    "    print(f'{len(uni_vc[uni_vc > 1])} not unique')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35948059-7502-4e1d-8855-8b82d9d3b039",
   "metadata": {},
   "source": [
    "## Each region (excluding divs) must have a valid parent which it is contained by and labelled by region key as within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0c699af-c137-4323-80b3-94f7a7dbb6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of errors: 0\n",
      "No errors found.\n"
     ]
    }
   ],
   "source": [
    "errors = validate_region_parents(unions, upazilas, 'upa')\n",
    "\n",
    "total_errors = sum(len(err_dict['errors']) for err_dict in errors)\n",
    "print(f'Total number of errors: {total_errors}')\n",
    "\n",
    "if total_errors == 0:\n",
    "    print(\"No errors found.\")\n",
    "else:\n",
    "    print(f\"Errors found: {total_errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eb3558-af69-4309-bf2b-ca1b39313e06",
   "metadata": {},
   "source": [
    "## Regions must not overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bf312fd-e03c-4323-a35c-2d771cf507e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlaps = find_overlapping_regions(unions)\n",
    "\n",
    "# if overlaps:\n",
    "#     print(\"Overlapping regions found:\")\n",
    "#     for pair in overlaps:\n",
    "#         print(f\"Region {pair[0]} overlaps with Region {pair[1]}\")\n",
    "# else:\n",
    "#     print(\"No overlapping regions found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b556a5ca-aefc-4877-bb5f-94e726ccfaba",
   "metadata": {},
   "source": [
    "## Regions must be completely contained by parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3899ba24-8d09-42a6-bda9-275665eb907a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No containment issues\n"
     ]
    }
   ],
   "source": [
    "containment_issues = check_individual_containment(unions, upazilas)\n",
    "\n",
    "if len(containment_issues) > 0:\n",
    "    print(f'{len(containment_issues)} containment issues found:')\n",
    "    for issue in containment_issues:\n",
    "        print(issue)\n",
    "else:\n",
    "    print(\"No containment issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4d3411-abc5-4020-9caa-db3844fcbee4",
   "metadata": {},
   "source": [
    "## Regions must not contain gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1069292-d930-4e45-90e4-a9a81ebb46f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No parent gap issues\n"
     ]
    }
   ],
   "source": [
    "containment_issues = check_region_containment(upazilas, districts)\n",
    "\n",
    "if len(containment_issues) > 0:\n",
    "    print(f'{len(containment_issues)} containment issues found:')\n",
    "    for issue in containment_issues:\n",
    "        print(issue)\n",
    "else:\n",
    "    print(\"No parent gap issues\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ae33b92-8c56-4cc4-9d34-0e94d4646482",
   "metadata": {},
   "source": [
    "# Mouzas\n",
    "\n",
    "Mouza maps include big Dhaka region that needs to be fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0eb91247-8a20-4d58-8c07-2bd5ea062316",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = mouzas.copy()\n",
    "unc = unions.copy()\n",
    "\n",
    "# Drop items with no geometry\n",
    "mc = mc.dropna(subset=['geometry'])\n",
    "\n",
    "# add area to mouca df\n",
    "mc['area'] = mc['geometry'].area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a61bf4e-6df5-4a62-b6cb-a70d0c5d2b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Index: 137 entries, 1464 to 1666\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   region_key  137 non-null    object  \n",
      " 1   geometry    137 non-null    geometry\n",
      " 2   div         137 non-null    object  \n",
      " 3   dis         137 non-null    object  \n",
      " 4   upa         137 non-null    object  \n",
      " 5   uni         137 non-null    object  \n",
      " 6   area        137 non-null    float64 \n",
      "dtypes: float64(1), geometry(1), object(5)\n",
      "memory usage: 8.6+ KB\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Index: 58187 entries, 0 to 58187\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   area        58187 non-null  float64 \n",
      " 1   div         58155 non-null  object  \n",
      " 2   dis         58158 non-null  object  \n",
      " 3   upa         58157 non-null  object  \n",
      " 4   uni         58154 non-null  object  \n",
      " 5   mou         57097 non-null  object  \n",
      " 6   geometry    58187 non-null  geometry\n",
      " 7   region_key  57094 non-null  object  \n",
      "dtypes: float64(1), geometry(1), object(6)\n",
      "memory usage: 4.0+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kk/Library/Caches/pypoetry/virtualenvs/experiments-83HLqO2c-py3.11/lib/python3.11/site-packages/geopandas/array.py:1638: UserWarning: CRS not set for some of the concatenation inputs. Setting output's CRS as WGS 84 / UTM zone 45N (the single non-null crs provided).\n",
      "  return GeometryArray(data, crs=_get_common_crs(to_concat))\n"
     ]
    }
   ],
   "source": [
    "# find big mouza, visually identified in qgis\n",
    "big_mou = mc[\n",
    "    (mc['div'] == 'Dhaka') & \n",
    "    (mc['dis'] == 'Dhaka') & \n",
    "    (mc['upa'].isnull()) & \n",
    "    (mc['uni'].isnull()) & \n",
    "    (mc['mou'].isnull())\n",
    "]\n",
    "\n",
    "# find unions within big mou\n",
    "unis_within_big_mou = unc[unc['geometry'].centroid.within(big_mou['geometry'].iloc[0])].copy().to_crs(epsg=32645)\n",
    "unis_within_big_mou.info()\n",
    "mc.info()\n",
    "unis_within_big_mou['mou'] = unis_within_big_mou['uni']\n",
    "mc = pd.concat([mc, unis_within_big_mou], ignore_index=True)\n",
    "\n",
    "# reset region key\n",
    "mc['region_key'] = mc['div'] + '@' + mc['dis'] + '@' + mc['upa'] + '@' + mc['uni'] + '@' + mc['mou']\n",
    "\n",
    "# remove big mouza\n",
    "mc = mc[~(\n",
    "    (mc['div'] == 'Dhaka') & \n",
    "    (mc['dis'] == 'Dhaka') & \n",
    "    (mc['upa'].isnull()) & \n",
    "    (mc['uni'].isnull()) & \n",
    "    (mc['mou'].isnull())\n",
    ")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5223860-c8cd-43d0-956e-696f5f4e39e9",
   "metadata": {},
   "source": [
    "## Region keys must be complete, containing no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d1edaa-f394-4d0f-8ab2-f5841cdd9c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unc['centroid'] = unc['geometry'].centroid\n",
    "\n",
    "# Fill missing values for 'div', 'dis', 'upa', and 'uni'\n",
    "count = 0\n",
    "for i, m in mc.iterrows():\n",
    "    count += 1\n",
    "\n",
    "    if count % 500 == 0:\n",
    "        print(f\"Processing row {count} / {len(mc)}\")\n",
    "    parent, _ = find_best_parent(m['geometry'], unc)\n",
    "    if parent is None:\n",
    "        # if mouza is not within a union, add its geometry\n",
    "        # to the nearest union by centroid\n",
    "        m_centroid = m['geometry'].centroid\n",
    "        unc['distance_to_geometry'] = unc['centroid'].apply(lambda x: m_centroid.distance(x))\n",
    "        nearest_union = unc.sort_values(by='distance_to_geometry').head(1).index[0]\n",
    "\n",
    "        # expand union to include parentless mouza\n",
    "        unc.at[nearest_union, 'geometry'] = unc.loc[nearest_union, 'geometry'].union(m['geometry'])\n",
    "        parent, _ = find_best_parent(m['geometry'], unc)\n",
    "\n",
    "        if parent is None:\n",
    "            print(f'still no parent for {i} after merging geometry to nearest union')\n",
    "\n",
    "    mc.at[i, 'div'] = parent['div']\n",
    "    mc.at[i, 'dis'] = parent['dis']\n",
    "    mc.at[i, 'upa'] = parent['upa']\n",
    "    mc.at[i, 'uni'] = parent['uni']\n",
    "\n",
    "print('step 1')\n",
    "# List to store new merged mouzas\n",
    "rows_to_add = []\n",
    "rows_to_remove = []\n",
    "\n",
    "# Handle merging of mouzas within the same union\n",
    "for upa_uni, union_group in mc.groupby(['upa', 'uni']):\n",
    "    mouza_missing = union_group[union_group['mou'].isnull()]\n",
    "\n",
    "    if len(mouza_missing) == 0:\n",
    "        continue\n",
    "\n",
    "    if len(mouza_missing) == 1:\n",
    "        # If there is only one mouza missing, set its 'mou' to the 'uni' value\n",
    "        mouza_index = mouza_missing.index[0]\n",
    "        mc.at[mouza_index, 'mou'] = mc.loc[mouza_index, 'uni']\n",
    "        continue\n",
    "    \n",
    "    # Merge geometries of all mouza_missing into a single polygon\n",
    "    merged_geometry = mouza_missing.geometry.union_all()\n",
    "    \n",
    "    # Create a new row for the merged mouza\n",
    "    new_row = {\n",
    "        'div': mouza_missing['div'].iloc[0],\n",
    "        'dis': mouza_missing['dis'].iloc[0],\n",
    "        'upa': mouza_missing['upa'].iloc[0],\n",
    "        'uni': mouza_missing['uni'].iloc[0],\n",
    "        'mou': mouza_missing['uni'].iloc[0],\n",
    "        'geometry': merged_geometry\n",
    "    }\n",
    "    \n",
    "    # Append new row to rows_to_add\n",
    "    rows_to_add.append(new_row)\n",
    "    \n",
    "    # Collect the mouzas to be removed\n",
    "    rows_to_remove.extend(mouza_missing.index.tolist())\n",
    "\n",
    "print('step 2')\n",
    "\n",
    "# Remove all rows that were merged\n",
    "mc = mc.drop(rows_to_remove)\n",
    "\n",
    "# Convert rows_to_add into a DataFrame and append to the existing DataFrame\n",
    "merged_mouzas_df = pd.DataFrame(rows_to_add)\n",
    "mc = pd.concat([mc, merged_mouzas_df], ignore_index=True)\n",
    "\n",
    "# Update region_key column\n",
    "mc['region_key'] = mc['div'] + '@' + mc['dis'] + '@' + mc['upa'] + '@' + mc['uni'] + '@' + mc['mou']\n",
    "\n",
    "# Merge rows with duplicate region_key\n",
    "rows_to_add = []\n",
    "rows_to_remove = []\n",
    "\n",
    "# Identify and merge rows with duplicate region_key\n",
    "for region_key, group in mc.groupby('region_key'):\n",
    "    if len(group) > 1:\n",
    "        # Merge geometries of duplicates\n",
    "        merged_geometry = group.geometry.union_all()\n",
    "\n",
    "        # Create new row for merged region\n",
    "        new_row = {\n",
    "            'div': group['div'].iloc[0],\n",
    "            'dis': group['dis'].iloc[0],\n",
    "            'upa': group['upa'].iloc[0],\n",
    "            'uni': group['uni'].iloc[0],\n",
    "            'mou': group['mou'].iloc[0],\n",
    "            'geometry': merged_geometry,\n",
    "            'region_key': region_key\n",
    "        }\n",
    "\n",
    "        # Append new row to rows_to_add\n",
    "        rows_to_add.append(new_row)\n",
    "\n",
    "        # Collect the original rows to be removed\n",
    "        rows_to_remove.extend(group.index.tolist())\n",
    "\n",
    "# Remove duplicate rows\n",
    "mc = mc.drop(rows_to_remove)\n",
    "\n",
    "# Add merged rows\n",
    "merged_regions_df = pd.DataFrame(rows_to_add)\n",
    "mc = pd.concat([mc, merged_regions_df], ignore_index=True)\n",
    "\n",
    "# Update region_key column\n",
    "mc['region_key'] = mc['div'] + '@' + mc['dis'] + '@' + mc['upa'] + '@' + mc['uni'] + '@' + mc['mou']\n",
    "# Output the resulting DataFrame info\n",
    "mc.info()\n",
    "\n",
    "# Check if there are still any mouzas without names\n",
    "unnamed_mouzas = mc[mc['mou'].isnull()]\n",
    "print(f'Number of unnamed mouzas: {len(unnamed_mouzas)}')\n",
    "\n",
    "if len(unnamed_mouzas) > 0:\n",
    "    print(unnamed_mouzas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7413ff2-61db-4f79-bcf9-a66b92e06676",
   "metadata": {},
   "source": [
    "## Region keys must be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a5e0e-b060-4c11-8d39-e5232ba86bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mou_vc = mc['region_key'].value_counts()\n",
    "\n",
    "if len(mou_vc[mou_vc > 1]) == 0:\n",
    "    print('mouza region keys unique')\n",
    "else:\n",
    "    print(f'{len(mou_vc[mou_vc > 1])} not unique')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973b5019-b695-4b56-8f5d-8f362368c75b",
   "metadata": {},
   "source": [
    "## Each region (excluding divs) must have a valid parent which it is contained by and labelled by region key as within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6a3d7a-d2ef-4576-ace5-b6855508944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = validate_region_parents(mc, unc, 'uni')\n",
    "\n",
    "total_errors = sum(len(err_dict['errors']) for err_dict in errors)\n",
    "print(f'Total number of errors: {total_errors}')\n",
    "\n",
    "if total_errors == 0:\n",
    "    print(\"No errors found.\")\n",
    "else:\n",
    "    print(f\"Errors found: {total_errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf7b90c-8cc6-4b20-93bb-d49f26811f26",
   "metadata": {},
   "source": [
    "## Regions must not overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d57f18-b94c-4d67-86e7-f705737a94dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_chunks = 128\n",
    "chunks = [[] for _ in range(num_chunks)]\n",
    "for i, row in mc.iterrows():\n",
    "    chunk_index = i % num_chunks\n",
    "    chunks[chunk_index].append(row)\n",
    "\n",
    "chunks = [pd.DataFrame(chunk) for chunk in chunks]\n",
    "\n",
    "overlaps = []\n",
    "for i in range(len(chunks)):\n",
    "    overlaps.extend(find_overlapping_regions(chunks[i]))\n",
    "\n",
    "if overlaps:\n",
    "    print(\"Overlapping regions found:\")\n",
    "    for pair in overlaps:\n",
    "        print(f\"Region {pair[0]} overlaps with Region {pair[1]}\")\n",
    "else:\n",
    "    print(\"No overlapping regions found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0264c623-1556-409b-824b-75c2c0b82c75",
   "metadata": {},
   "source": [
    "## Regions must be completely contained by parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b799dba9-0957-421e-b0a1-2162092e21d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "containment_issues = check_individual_containment(mc, unc, 0.9)\n",
    "\n",
    "if len(containment_issues) > 0:\n",
    "    print(f'{len(containment_issues)} containment issues found:')\n",
    "    \n",
    "    for issue in containment_issues:\n",
    "        print(issue)\n",
    "        \n",
    "        # Get labelled parent for the current issue\n",
    "        mouza_region_key = issue.split('\\n')[1].split(':')[1].strip()\n",
    "        mouza = mc[mc['region_key'] == mouza_region_key].iloc[0]\n",
    "        \n",
    "        labelled_parent = get_labelled_parent(\n",
    "            mouza,\n",
    "            unc,\n",
    "        )\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "        gpd.GeoDataFrame(geometry=[labelled_parent['geometry']]).plot(ax=ax, linewidth=2, edgecolor='red', facecolor='none', alpha=0.5)\n",
    "        gpd.GeoDataFrame(geometry=[mouza['geometry']]).plot(ax=ax, linewidth=1, edgecolor='blue', facecolor='none', alpha=0.5)\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        print('================================')\n",
    "\n",
    "else:\n",
    "    print(\"No containment issues\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a252e9da-ba86-41cf-942e-8a015e04bcbd",
   "metadata": {},
   "source": [
    "## Regions must not contain gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e9dc5b-b85d-4a74-b28a-5ea9cc2c0c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "containment_issues = check_region_containment(mc, unions)\n",
    "\n",
    "if len(containment_issues) > 0:\n",
    "    print(f'{len(containment_issues)} containment issues found:')\n",
    "    for issue in containment_issues:\n",
    "        print(issue)\n",
    "else:\n",
    "    print(\"No parent gap issues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bbef01-d13b-4900-82ce-436f079273aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "divisions.to_file('div.geojson', driver='GeoJSON')\n",
    "districts.to_file('dis.geojson', driver='GeoJSON')\n",
    "upazilas.to_file('upa.geojson', driver='GeoJSON')\n",
    "unc.drop(columns=['centroid']).to_file('uni.geojson', driver='GeoJSON')\n",
    "mc.to_file('mou.geojson', driver='GeoJSON')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
